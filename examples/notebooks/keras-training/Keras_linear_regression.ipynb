{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py35_int64/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf_encrypted as tfe\n",
    "\n",
    "from tensorflow.keras.losses import MeanSquaredError as tf_MeanSquaredError\n",
    "from tensorflow.keras.optimizers import SGD as tf_SGD\n",
    "\n",
    "from tf_encrypted.keras.losses import Loss\n",
    "from tf_encrypted.keras import backend as KE\n",
    "from tf_encrypted.keras.optimizers import SGD\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate random data-set\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(2000, 1)\n",
    "y = 1 + 4 * x + np.random.rand(2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = x[:1500], y[:1500]\n",
    "X_valid, y_valid = x[1500:], y[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1\n",
    "training_set_size = 1500\n",
    "test_set_size = 500\n",
    "batch_size = 100\n",
    "steps_per_epoch = (training_set_size // batch_size)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plaintext Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py35_int64/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py35_int64/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf_model = tf.keras.Sequential()\n",
    "tf_model.add(tf.keras.layers.Dense(1, input_shape=[num_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py35_int64/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py35_int64/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py35_int64/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/py35_int64/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 7.4582\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 707us/step - loss: 3.6236\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 755us/step - loss: 1.8455\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 829us/step - loss: 1.0184\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 932us/step - loss: 0.6312\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.4475\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.3581\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 986us/step - loss: 0.3125\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2873\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 899us/step - loss: 0.2717\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2607\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 999us/step - loss: 0.2519\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2444\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2375\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2311\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2251\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 892us/step - loss: 0.2193\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2138\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.2085\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 874us/step - loss: 0.2034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x114123780>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.compile(optimizer=tf_SGD(lr=0.01),\n",
    "                 loss=tf_MeanSquaredError())\n",
    "\n",
    "tf_model.fit(X_train,\n",
    "             y_train,\n",
    "             epochs=20,\n",
    "             steps_per_epoch=steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Private Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataOwner:\n",
    "  \"\"\"Contains code meant to be executed by a data owner Player.\"\"\"\n",
    "  def __init__(\n",
    "      self,\n",
    "      player_name,\n",
    "      num_features,\n",
    "      training_set_size,\n",
    "      test_set_size,\n",
    "      batch_size\n",
    "  ):\n",
    "    self.player_name = player_name\n",
    "    self.num_features = num_features\n",
    "    self.training_set_size = training_set_size\n",
    "    self.test_set_size = test_set_size\n",
    "    self.batch_size = batch_size\n",
    "    self.train_initializer = None\n",
    "    self.test_initializer = None\n",
    "\n",
    "  @property\n",
    "  def initializer(self):\n",
    "    return tf.group(self.train_initializer, self.test_initializer)\n",
    "\n",
    "  @tfe.local_computation\n",
    "  def provide_training_data(self):\n",
    "    \"\"\"Preprocess training dataset\n",
    "\n",
    "    Return single batch of training dataset\n",
    "    \"\"\"\n",
    "    def norm(x, y):\n",
    "      return tf.cast(x, tf.float32), tf.expand_dims(y, 0)\n",
    "\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)) \\\n",
    "        .map(norm) \\\n",
    "        .repeat() \\\n",
    "        .shuffle(buffer_size=self.batch_size) \\\n",
    "        .batch(self.batch_size)\n",
    "\n",
    "    train_set_iterator = train_set.make_initializable_iterator()\n",
    "    self.train_initializer = train_set_iterator.initializer\n",
    "\n",
    "    x, y = train_set_iterator.get_next()\n",
    "    x = tf.reshape(x, [self.batch_size, self.num_features])\n",
    "    y = tf.reshape(y, [self.batch_size, 1])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "  @tfe.local_computation\n",
    "  def provide_testing_data(self):\n",
    "    \"\"\"Preprocess testing dataset\n",
    "\n",
    "    Return single batch of testing dataset\n",
    "    \"\"\"\n",
    "    def norm(x, y):\n",
    "      return tf.cast(x, tf.float32), tf.expand_dims(y, 0)\n",
    "\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid)) \\\n",
    "        .map(norm) \\\n",
    "        .batch(self.test_set_size)\n",
    "\n",
    "    test_set_iterator = test_set.make_initializable_iterator()\n",
    "    self.test_initializer = test_set_iterator.initializer\n",
    "\n",
    "    x, y = test_set_iterator.get_next()\n",
    "    x = tf.reshape(x, [self.test_set_size, self.num_features])\n",
    "    y = tf.reshape(y, [self.test_set_size, 1])\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_owner = DataOwner('data-owner',\n",
    "                       num_features,\n",
    "                       training_set_size,\n",
    "                       test_set_size,\n",
    "                       batch_size)\n",
    "\n",
    "x_train_pond, y_train_pond = data_owner.provide_training_data()\n",
    "x_valid_pond, y_valid_pond = data_owner.provide_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Loss):\n",
    "  \"\"\"Computes the MSE loss between true\n",
    "  labels and predicted labels.\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super(MSE, self).__init__(\n",
    "        mse)\n",
    "\n",
    "  def grad(self, y_true, y_pred):\n",
    "    batch_size = y_true.shape.as_list()[0] \n",
    "    batch_size_inv = 1 / batch_size  \n",
    "    return 2 * (y_pred - y_true) * batch_size_inv \n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    batch_size = y_true.shape.as_list()[0] \n",
    "    batch_size_inv = 1 / batch_size  \n",
    "    out = y_true - y_pred #Internally converts y_true to PondPrivateTensor\n",
    "    out=out.square() \n",
    "    mse_loss = out.reduce_sum(axis=0) * batch_size_inv # mean squared error\n",
    "    return  mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfe.keras.Sequential()\n",
    "model.add(tfe.keras.layers.Dense(1, batch_input_shape=[batch_size, num_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tf_encrypted:Players: ['server0', 'server1', 'server2', 'data-owner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 1s 490us/step - loss: 9.1494\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 4.4604\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 2.4138\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 1.3905\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.9516\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.6452\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 0s 74us/step - loss: 0.5274\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.4778\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.4231\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4134\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.4035\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3779\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3661\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 0s 75us/step - loss: 0.3414\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 0s 76us/step - loss: 0.3500\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3468\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.3186\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3202\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 0.3008\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.2915\n"
     ]
    }
   ],
   "source": [
    "sess = KE.get_session()\n",
    "sess.run([data_owner.initializer])\n",
    "\n",
    "model.compile(optimizer=SGD(lr=0.01),\n",
    "              loss=MSE())\n",
    "# Train\n",
    "model.fit(x_train_pond,\n",
    "          y_train_pond,\n",
    "          epochs=20,\n",
    "          steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
